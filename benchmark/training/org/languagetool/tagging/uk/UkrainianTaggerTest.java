/**
 * LanguageTool, a natural language style checker
 * Copyright (C) 2006 Daniel Naber (http://www.danielnaber.de)
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2.1 of the License, or (at your option) any later version.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301
 * USA
 */
package org.languagetool.tagging.uk;


import java.io.IOException;
import org.junit.Test;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.tokenizers.uk.UkrainianWordTokenizer;


public class UkrainianTaggerTest {
    private UkrainianTagger tagger;

    private UkrainianWordTokenizer tokenizer;

    @Test
    public void testDictionary() throws IOException {
        TestTools.testDictionary(tagger, new Ukrainian());
    }

    @Test
    public void testTagger() throws IOException {
        // one-way case sensitivity
        TestTools.myAssert("?????", "?????/[???]noun:inanim:m:v_dav|?????/[???]noun:inanim:m:v_mis", tokenizer, tagger);
        TestTools.myAssert("?????", "?????/[???]noun:anim:m:v_dav:prop:fname|?????/[???]noun:anim:m:v_mis:prop:fname|?????/[????]noun:inanim:m:v_mis:prop:geo|?????/[???]noun:inanim:m:v_dav|?????/[???]noun:inanim:m:v_mis", tokenizer, tagger);
        TestTools.myAssert("???", "???/[???]noun:anim:m:v_naz", tokenizer, tagger);
        TestTools.myAssert("???", "???/[???]noun:anim:m:v_naz", tokenizer, tagger);
        TestTools.myAssert("???", "???/[???]noun:inanim:m:v_dav:nv:np:abbr|???/[???]noun:inanim:m:v_kly:nv:np:abbr|???/[???]noun:inanim:m:v_mis:nv:np:abbr|???/[???]noun:inanim:m:v_naz:nv:np:abbr|???/[???]noun:inanim:m:v_oru:nv:np:abbr|???/[???]noun:inanim:m:v_rod:nv:np:abbr|???/[???]noun:inanim:m:v_zna:nv:np:abbr|???/[???]noun:anim:m:v_naz", tokenizer, tagger);
        TestTools.myAssert("????", "????/[????]noun:inanim:f:v_dav|????/[????]noun:inanim:f:v_mis|????/[????]noun:inanim:f:v_rod|????/[????]noun:inanim:p:v_kly|????/[????]noun:inanim:p:v_naz|????/[????]noun:inanim:p:v_zna|????/[????]adv:compc:&predic", tokenizer, tagger);
        TestTools.myAssert("????", ("????/[????]noun:anim:m:v_mis:prop:lname|????/[????]noun:anim:m:v_dav:nv:np:prop:lname|????/[????]noun:anim:m:v_kly:nv:np:prop:lname|????/[????]noun:anim:m:v_mis:nv:np:prop:lname|????/[????]noun:anim:m:v_naz:nv:np:prop:lname|????/[????]noun:anim:m:v_oru:nv:np:prop:lname" + "|????/[????]noun:anim:m:v_rod:nv:np:prop:lname|????/[????]noun:anim:m:v_zna:nv:np:prop:lname|????/[????]noun:inanim:f:v_dav|????/[????]noun:inanim:f:v_mis|????/[????]noun:inanim:f:v_rod|????/[????]noun:inanim:p:v_kly|????/[????]noun:inanim:p:v_naz|????/[????]noun:inanim:p:v_zna|????/[????]adv:compc:&predic"), tokenizer, tagger);
        TestTools.myAssert("???", "???/[???]noun:anim:m:v_naz:prop:fname|???/[???]part:pers", tokenizer, tagger);
        TestTools.myAssert("???", "???/[???]part:pers", tokenizer, tagger);
        TestTools.myAssert("?????? ???????? ?????", "??????/[??????]noun:inanim:f:v_zna -- ????????/[????????]verb:perf:impers -- ?????/[???]noun:inanim:m:v_oru|?????/[??????]noun:inanim:p:v_rod", tokenizer, tagger);
        String expected = "?????/[?????]adv -- ???/[???]numr:p:v_naz|???/[???]numr:p:v_zna -- ????/[???]noun:inanim:p:v_kly|????/[???]noun:inanim:p:v_naz|????/[???]noun:inanim:p:v_zna" + (((((" -- ????/[??]noun:inanim:n:v_dav:&pron:dem|????/[??]noun:inanim:n:v_mis:&pron:dem|????/[???]adj:m:v_dav:&pron:dem|????/[???]adj:m:v_mis:&pron:dem|????/[???]adj:n:v_dav:&pron:dem|????/[???]adj:n:v_mis:&pron:dem|????/[???]noun:inanim:m:v_dav|????/[???]noun:inanim:m:v_mis|????/[???]noun:inanim:m:v_rod|????/[????]adv|????/[????]conj:subord" + " -- ????/[????]noun:anim:f:v_naz:prop:fname|????/[?????]adj:f:v_kly:compb|????/[?????]adj:f:v_naz:compb -- ?????/[???]noun:inanim:m:v_oru|?????/[?????]adv -- ??/[??]prep") + " -- ?????????/[???????]noun:anim:m:v_oru:xp1|?????????/[???????]noun:anim:m:v_oru:xp2 -- ????????/[??????]noun:anim:m:v_oru:prop:fname -- ???????/[???????]verb:perf:past:p -- ????/[????]adv:&pron:dem") + " -- ??/[??]intj|??/[??]part|??/[??]prep -- ") + "??????????/[??????????]noun:inanim:n:v_kly|??????????/[??????????]noun:inanim:n:v_naz|??????????/[??????????]noun:inanim:n:v_rod|??????????/[??????????]noun:inanim:n:v_zna") + "|??????????/[??????????]noun:inanim:p:v_kly|??????????/[??????????]noun:inanim:p:v_naz|??????????/[??????????]noun:inanim:p:v_zna");
        TestTools.myAssert("????? ??? ???? ???? ???? ????? ?? ????????? ???????? ??????? ???? ?? ??????????.", expected, tokenizer, tagger);
        assertNotTagged("????");
    }

    @Test
    public void testNumberTagging() throws IOException {
        TestTools.myAssert("101,234", "101,234/[101,234]number", tokenizer, tagger);
        TestTools.myAssert("101 234", "101 234/[101 234]number", tokenizer, tagger);
        TestTools.myAssert("3,5-5,6% 7? 7,4??", "3,5-5,6%/[3,5-5,6%]number -- 7?/[7?]number -- 7,4??/[7,4??]number", tokenizer, tagger);
        TestTools.myAssert("XIX", "XIX/[XIX]number", tokenizer, tagger);
        TestTools.myAssert("10?15", "10?15/[10?15]number", tokenizer, tagger);
        TestTools.myAssert("14.07.2001", "14.07.2001/[14.07.2001]date", tokenizer, tagger);
        TestTools.myAssert("? 15.33", "?/[?]intj|?/[?]prep -- 15.33/[15.33]time", tokenizer, tagger);
        TestTools.myAssert("? 1:05", "?/[?]intj|?/[?]prep -- 1:05/[1:05]time", tokenizer, tagger);
    }

    @Test
    public void testSpecialSymbols() throws IOException {
        TestTools.myAssert("???", ("???/[??]noun:inanim:m:v_dav:nv:abbr|???/[??]noun:inanim:m:v_kly:nv:abbr|???/[??]noun:inanim:m:v_mis:nv:abbr|???/[??]noun:inanim:m:v_naz:nv:abbr|???/[??]noun:inanim:m:v_oru:nv:abbr" + ("|???/[??]noun:inanim:m:v_rod:nv:abbr|???/[??]noun:inanim:m:v_zna:nv:abbr|???/[??]noun:inanim:p:v_dav:nv:abbr|???/[??]noun:inanim:p:v_kly:nv:abbr" + "|???/[??]noun:inanim:p:v_mis:nv:abbr|???/[??]noun:inanim:p:v_naz:nv:abbr|???/[??]noun:inanim:p:v_oru:nv:abbr|???/[??]noun:inanim:p:v_rod:nv:abbr|???/[??]noun:inanim:p:v_zna:nv:abbr")), tokenizer, tagger);
    }

    @Test
    public void testTaggingWithDots() throws IOException {
        TestTools.myAssert("300 ?. ?? ?. ?.", ("300/[300]number -- ?./[?.]noun:inanim:f:v_dav:nv:np:abbr|?./[?.]noun:inanim:f:v_mis:nv:np:abbr|?./[?.]noun:inanim:f:v_naz:nv:np:abbr|?./[?.]noun:inanim:f:v_oru:nv:np:abbr" + ((((((((((("|?./[?.]noun:inanim:f:v_rod:nv:np:abbr|?./[?.]noun:inanim:f:v_zna:nv:np:abbr|?./[?.]noun:inanim:m:v_dav:nv:np:abbr|?./[?.]noun:inanim:m:v_mis:nv:np:abbr" + "|?./[?.]noun:inanim:m:v_naz:nv:np:abbr|?./[?.]noun:inanim:m:v_oru:nv:np:abbr|?./[?.]noun:inanim:m:v_rod:nv:np:abbr|?./[?.]noun:inanim:m:v_zna:nv:np:abbr") + " -- ??/[??]noun:inanim:n:v_dav:nv|??/[??]noun:inanim:n:v_kly:nv|??/[??]noun:inanim:n:v_mis:nv|??/[??]noun:inanim:n:v_naz:nv|??/[??]noun:inanim:n:v_oru:nv") + "|??/[??]noun:inanim:n:v_rod:nv|??/[??]noun:inanim:n:v_zna:nv|??/[??]noun:inanim:p:v_dav:nv|??/[??]noun:inanim:p:v_kly:nv|??/[??]noun:inanim:p:v_mis:nv") + "|??/[??]noun:inanim:p:v_naz:nv|??/[??]noun:inanim:p:v_oru:nv|??/[??]noun:inanim:p:v_rod:nv|??/[??]noun:inanim:p:v_zna:nv|??/[??]prep") + " -- ?./[?.]adj:f:v_dav:nv:abbr|?./[?.]adj:f:v_mis:nv:abbr|?./[?.]adj:f:v_naz:nv:abbr|?./[?.]adj:f:v_oru:nv:abbr|?./[?.]adj:f:v_rod:nv:abbr|?./[?.]adj:f:v_zna:nv:abbr") + "|?./[?.]adj:m:v_dav:nv:abbr|?./[?.]adj:m:v_mis:nv:abbr|?./[?.]adj:m:v_naz:nv:abbr|?./[?.]adj:m:v_oru:nv:abbr|?./[?.]adj:m:v_rod:nv:abbr|?./[?.]adj:m:v_zna:nv:abbr") + "|?./[?.]adj:n:v_dav:nv:abbr|?./[?.]adj:n:v_mis:nv:abbr|?./[?.]adj:n:v_naz:nv:abbr|?./[?.]adj:n:v_oru:nv:abbr|?./[?.]adj:n:v_rod:nv:abbr|?./[?.]adj:n:v_zna:nv:abbr") + "|?./[?.]adj:p:v_dav:nv:abbr|?./[?.]adj:p:v_mis:nv:abbr|?./[?.]adj:p:v_naz:nv:abbr|?./[?.]adj:p:v_oru:nv:abbr|?./[?.]adj:p:v_rod:nv:abbr|?./[?.]adj:p:v_zna:nv:abbr") + " -- ?./[?.]noun:inanim:f:v_dav:nv:abbr|?./[?.]noun:inanim:f:v_mis:nv:abbr|?./[?.]noun:inanim:f:v_naz:nv:abbr|?./[?.]noun:inanim:f:v_oru:nv:abbr|?./[?.]noun:inanim:f:v_rod:nv:abbr") + "|?./[?.]noun:inanim:f:v_zna:nv:abbr|?./[?.]noun:inanim:p:v_dav:nv:abbr|?./[?.]noun:inanim:p:v_mis:nv:abbr|?./[?.]noun:inanim:p:v_naz:nv:abbr|?./[?.]noun:inanim:p:v_oru:nv:abbr") + "|?./[?.]noun:inanim:p:v_rod:nv:abbr|?./[?.]noun:inanim:p:v_zna:nv:abbr")), tokenizer, tagger);
        TestTools.myAssert("300 ???. ???????", "300/[300]number -- ???./[???.]noun:inanim:f:v_dav:nv:&&numr:abbr|???./[???.]noun:inanim:f:v_mis:nv:&&numr:abbr|???./[???.]noun:inanim:f:v_naz:nv:&&numr:abbr|???./[???.]noun:inanim:f:v_oru:nv:&&numr:abbr|???./[???.]noun:inanim:f:v_rod:nv:&&numr:abbr|???./[???.]noun:inanim:f:v_zna:nv:&&numr:abbr|???./[???.]noun:inanim:p:v_dav:nv:&&numr:abbr|???./[???.]noun:inanim:p:v_mis:nv:&&numr:abbr|???./[???.]noun:inanim:p:v_naz:nv:&&numr:abbr|???./[???.]noun:inanim:p:v_oru:nv:&&numr:abbr|???./[???.]noun:inanim:p:v_rod:nv:&&numr:abbr|???./[???.]noun:inanim:p:v_zna:nv:&&numr:abbr -- ???????/[??????]noun:inanim:p:v_rod", tokenizer, tagger);
        TestTools.myAssert("??????? (??????????-????????. ? ???.) ????? ??????????.", ("???????/[???????]noun:anim:m:v_naz:prop:fname -- ??????????-????????/[??????????-????????]noun:anim:m:v_naz -- ???./[???.]noun:inanim:m:v_naz:abbr" + // "???????/[???????]noun:anim:m:v_naz:prop:fname -- ??????????-????????/[??????????-????????]noun:anim:m:v_naz -- ???./[null]null"
        " -- ?????/[????]noun:inanim:m:v_kly:xp1|?????/[????]noun:inanim:m:v_kly:xp2|?????/[???????]verb:perf:futr:s:3|?????/[?????]verb:perf:futr:s:3 -- ??????????/[????????]noun:anim:m:v_oru"), tokenizer, tagger);
        // TestTools.myAssert("???????? (? ??????. - ???.), ??????.",
        // "????????/[????????]adv -- ?/[?]prep -- ??????/[??????]noun:inanim:m:v_naz|??????/[??????]noun:inanim:m:v_zna -- "
        // +"???./[???.]noun:inanim:f:v_dav:nv:abbr|???./[???.]noun:inanim:f:v_mis:nv:abbr|???./[???.]noun:inanim:f:v_naz:nv:abbr|???./[???.]noun:inanim:f:v_oru:nv:abbr|???./[???.]noun:inanim:f:v_rod:nv:abbr|???./[???.]noun:inanim:f:v_zna:nv:abbr|???./[???.]noun:inanim:m:v_naz:abbr|???./[???.]noun:inanim:p:v_dav:nv:abbr|???./[???.]noun:inanim:p:v_mis:nv:abbr|???./[???.]noun:inanim:p:v_naz:nv:abbr|???./[???.]noun:inanim:p:v_oru:nv:abbr|???./[???.]noun:inanim:p:v_rod:nv:abbr|???./[???.]noun:inanim:p:v_zna:nv:abbr -- ??????/[??????]adv",
        // tokenizer, tagger);
        TestTools.myAssert("?. ????????.", "?./[null]null -- ????????/[???????]noun:anim:m:v_rod:prop:lname|????????/[???????]noun:anim:m:v_zna:prop:lname|????????/[????????]noun:anim:f:v_naz:prop:lname", tokenizer, tagger);
    }

    @Test
    public void testProperNameAllCaps() throws IOException {
        TestTools.myAssert("???????", "???????/[???????]noun:inanim:f:v_naz:prop:geo", tokenizer, tagger);
        TestTools.myAssert("?????", "?????/[?????]noun:inanim:f:v_zna:prop:geo|?????/[??????]verb:imperf:pres:s:1", tokenizer, tagger);
        assertNotTagged("?????");
    }

    @Test
    public void testDynamicTaggingNums() throws IOException {
        TestTools.myAssert("100-???????", "100-???????/[100-??????]adj:m:v_dav|100-???????/[100-??????]adj:m:v_mis|100-???????/[100-??????]adj:n:v_dav|100-???????/[100-??????]adj:n:v_mis", tokenizer, tagger);
        TestTools.myAssert("1-2-???????????", "1-2-???????????/[1-2-???????????]adj:m:v_oru|1-2-???????????/[1-2-???????????]adj:n:v_oru|1-2-???????????/[1-2-???????????]adj:p:v_dav", tokenizer, tagger);
        TestTools.myAssert("10-?????????", "10-?????????/[10-???????]noun:anim:p:v_rod|10-?????????/[10-???????]noun:anim:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("10-????????", "10-????????/[10-????????]noun:inanim:f:v_naz", tokenizer, tagger);
        TestTools.myAssert("11-12-??????", "11-12-??????/[11-12-??????]adj:m:v_kly|11-12-??????/[11-12-??????]adj:m:v_naz|11-12-??????/[11-12-??????]adj:m:v_zna:rinanim", tokenizer, tagger);
        TestTools.myAssert("100-?", "100-?/[100-?]adj:f:v_dav:&numr|100-?/[100-?]adj:f:v_mis:&numr|100-?/[100-?]adj:m:v_naz:&numr|100-?/[100-?]adj:m:v_zna:rinanim:&numr", tokenizer, tagger);
        TestTools.myAssert("50-?", "50-?/[50-?]adj:p:v_mis:&numr|50-?/[50-?]adj:p:v_rod:&numr|50-?/[50-?]adj:p:v_zna:ranim:&numr", tokenizer, tagger);
        TestTools.myAssert("11-??", "11-??/[11-?]adj:f:v_zna:&numr", tokenizer, tagger);
        TestTools.myAssert("3-??", "3-??/[3-?]adj:f:v_dav:&numr|3-??/[3-?]adj:f:v_mis:&numr|3-??/[3-?]adj:m:v_naz:&numr|3-??/[3-?]adj:m:v_zna:rinanim:&numr", tokenizer, tagger);
        TestTools.myAssert("5-??", "5-??/[5-?]adj:f:v_dav:&numr|5-??/[5-?]adj:f:v_mis:&numr", tokenizer, tagger);
        // n-dash
        TestTools.myAssert("54??????", "54??????/[54-??????]adj:f:v_kly|54??????/[54-??????]adj:f:v_naz", tokenizer, tagger);
        assertNotTagged("54????");
        TestTools.myAssert("15-??", "15-??/[15]numr:p:v_dav:bad|15-??/[15]numr:p:v_mis:bad|15-??/[15]numr:p:v_rod:bad", tokenizer, tagger);
        TestTools.myAssert("100-?????", "100-?????/[100-?????]noun:inanim:n:v_kly|100-?????/[100-?????]noun:inanim:n:v_naz|100-?????/[100-?????]noun:inanim:n:v_rod|100-?????/[100-?????]noun:inanim:n:v_zna|100-?????/[100-?????]noun:inanim:p:v_kly|100-?????/[100-?????]noun:inanim:p:v_naz|100-?????/[100-?????]noun:inanim:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("100-????????", "100-????????/[100-????????]noun:inanim:f:v_naz", tokenizer, tagger);
        TestTools.myAssert("100-??????????", "100-??????????/[100-??????????]adv", tokenizer, tagger);
        TestTools.myAssert("120-??", ("120-??/[120-??]adj:f:v_dav|120-??/[120-??]adj:f:v_mis|120-??/[120-??]adj:f:v_naz|120-??/[120-??]adj:f:v_oru|120-??/[120-??]adj:f:v_rod|120-??/[120-??]adj:f:v_zna" + (("|120-??/[120-??]adj:m:v_dav|120-??/[120-??]adj:m:v_mis|120-??/[120-??]adj:m:v_naz|120-??/[120-??]adj:m:v_oru|120-??/[120-??]adj:m:v_rod|120-??/[120-??]adj:m:v_zna" + "|120-??/[120-??]adj:n:v_dav|120-??/[120-??]adj:n:v_mis|120-??/[120-??]adj:n:v_naz|120-??/[120-??]adj:n:v_oru|120-??/[120-??]adj:n:v_rod|120-??/[120-??]adj:n:v_zna") + "|120-??/[120-??]adj:p:v_dav|120-??/[120-??]adj:p:v_mis|120-??/[120-??]adj:p:v_naz|120-??/[120-??]adj:p:v_oru|120-??/[120-??]adj:p:v_rod|120-??/[120-??]adj:p:v_zna")), tokenizer, tagger);
    }

    @Test
    public void testNumberedEntities() throws IOException {
        TestTools.myAssert("????-2014", "????-2014/[????-2014]noun:inanim:m:v_dav:nv:prop|????-2014/[????-2014]noun:inanim:m:v_mis:nv:prop|????-2014/[????-2014]noun:inanim:m:v_naz:nv:prop|????-2014/[????-2014]noun:inanim:m:v_oru:nv:prop|????-2014/[????-2014]noun:inanim:m:v_rod:nv:prop|????-2014/[????-2014]noun:inanim:m:v_zna:nv:prop", tokenizer, tagger);
        TestTools.myAssert("????-2014", "????-2014/[???-2014]noun:inanim:p:v_naz:prop|????-2014/[???-2014]noun:inanim:p:v_zna:prop", tokenizer, tagger);
        TestTools.myAssert("??-2014", "??-2014/[??-2014]noun:inanim:m:v_dav:nv:np:prop:abbr|??-2014/[??-2014]noun:inanim:m:v_mis:nv:np:prop:abbr|??-2014/[??-2014]noun:inanim:m:v_naz:nv:np:prop:abbr|??-2014/[??-2014]noun:inanim:m:v_oru:nv:np:prop:abbr|??-2014/[??-2014]noun:inanim:m:v_rod:nv:np:prop:abbr|??-2014/[??-2014]noun:inanim:m:v_zna:nv:np:prop:abbr", tokenizer, tagger);
        TestTools.myAssert("??????-2014", "??????-2014/[??????-2014]noun:inanim:m:v_naz:prop:xp2|??????-2014/[??????-2014]noun:inanim:m:v_zna:prop:xp2", tokenizer, tagger);
        TestTools.myAssert("?????-2014", "?????-2014/[?????-2014]noun:inanim:p:v_naz:prop:ns|?????-2014/[?????-2014]noun:inanim:p:v_zna:prop:ns", tokenizer, tagger);
        TestTools.myAssert("?????-2002", "?????-2002/[?????-2002]noun:inanim:m:v_naz:prop|?????-2002/[?????-2002]noun:inanim:m:v_zna:prop", tokenizer, tagger);
        TestTools.myAssert("??-140", "??-140/[??-140]noun:inanim:m:v_dav:nv|??-140/[??-140]noun:inanim:m:v_mis:nv|??-140/[??-140]noun:inanim:m:v_naz:nv|??-140/[??-140]noun:inanim:m:v_oru:nv|??-140/[??-140]noun:inanim:m:v_rod:nv|??-140/[??-140]noun:inanim:m:v_zna:nv|??-140/[??-140]noun:inanim:p:v_dav:nv|??-140/[??-140]noun:inanim:p:v_mis:nv|??-140/[??-140]noun:inanim:p:v_naz:nv|??-140/[??-140]noun:inanim:p:v_oru:nv|??-140/[??-140]noun:inanim:p:v_rod:nv|??-140/[??-140]noun:inanim:p:v_zna:nv", tokenizer, tagger);
        TestTools.myAssert("???-2104", "???-2104/[???-2104]noun:inanim:f:v_dav:nv|???-2104/[???-2104]noun:inanim:f:v_mis:nv|???-2104/[???-2104]noun:inanim:f:v_naz:nv|???-2104/[???-2104]noun:inanim:f:v_oru:nv|???-2104/[???-2104]noun:inanim:f:v_rod:nv|???-2104/[???-2104]noun:inanim:f:v_zna:nv|???-2104/[???-2104]noun:inanim:m:v_dav:nv|???-2104/[???-2104]noun:inanim:m:v_mis:nv|???-2104/[???-2104]noun:inanim:m:v_naz:nv|???-2104/[???-2104]noun:inanim:m:v_oru:nv|???-2104/[???-2104]noun:inanim:m:v_rod:nv|???-2104/[???-2104]noun:inanim:m:v_zna:nv|???-2104/[???-2104]noun:inanim:p:v_dav:nv|???-2104/[???-2104]noun:inanim:p:v_mis:nv|???-2104/[???-2104]noun:inanim:p:v_naz:nv|???-2104/[???-2104]noun:inanim:p:v_oru:nv|???-2104/[???-2104]noun:inanim:p:v_rod:nv|???-2104/[???-2104]noun:inanim:p:v_zna:nv", tokenizer, tagger);
        TestTools.myAssert("???-21?", "???-21?/[???-21?]noun:inanim:m:v_dav:nv|???-21?/[???-21?]noun:inanim:m:v_mis:nv|???-21?/[???-21?]noun:inanim:m:v_naz:nv|???-21?/[???-21?]noun:inanim:m:v_oru:nv|???-21?/[???-21?]noun:inanim:m:v_rod:nv|???-21?/[???-21?]noun:inanim:m:v_zna:nv|???-21?/[???-21?]noun:inanim:p:v_dav:nv|???-21?/[???-21?]noun:inanim:p:v_mis:nv|???-21?/[???-21?]noun:inanim:p:v_naz:nv|???-21?/[???-21?]noun:inanim:p:v_oru:nv|???-21?/[???-21?]noun:inanim:p:v_rod:nv|???-21?/[???-21?]noun:inanim:p:v_zna:nv", tokenizer, tagger);
        // TestTools.myAssert("??????2006", "??????2006/[?????-2006]noun:inanim:p:v_dav:prop:ns|??????2006/[?????-2006]noun:inanim:p:v_mis:prop:ns|??????2006/[?????-2006]noun:inanim:p:v_rod:prop:ns", tokenizer, tagger);
        TestTools.myAssert("???-10", "???-10/[???-10]noninfl", tokenizer, tagger);
        TestTools.myAssert("???????-1", "???????-1/[???????-1]noun:inanim:f:v_rod:prop|???????-1/[???????-1]noun:inanim:p:v_naz:prop|???????-1/[???????-1]noun:inanim:p:v_zna:prop", tokenizer, tagger);
        TestTools.myAssert("???????-2", "???????-2/[???????-2]noun:inanim:p:v_naz:prop:geo:ns|???????-2/[???????-2]noun:inanim:p:v_zna:prop:geo:ns", tokenizer, tagger);
        TestTools.myAssert("???-1", "???-1/[???-1]noun:inanim:f:v_dav:nv|???-1/[???-1]noun:inanim:f:v_mis:nv|???-1/[???-1]noun:inanim:f:v_naz:nv|???-1/[???-1]noun:inanim:f:v_oru:nv|???-1/[???-1]noun:inanim:f:v_rod:nv|???-1/[???-1]noun:inanim:f:v_zna:nv", tokenizer, tagger);
        TestTools.myAssert("?????-3", "?????-3/[?????-3]noun:inanim:f:v_dav:nv|?????-3/[?????-3]noun:inanim:f:v_mis:nv|?????-3/[?????-3]noun:inanim:f:v_naz:nv|?????-3/[?????-3]noun:inanim:f:v_oru:nv|?????-3/[?????-3]noun:inanim:f:v_rod:nv|?????-3/[?????-3]noun:inanim:f:v_zna:nv|?????-3/[?????-3]noun:inanim:p:v_dav:nv|?????-3/[?????-3]noun:inanim:p:v_mis:nv|?????-3/[?????-3]noun:inanim:p:v_naz:nv|?????-3/[?????-3]noun:inanim:p:v_oru:nv|?????-3/[?????-3]noun:inanim:p:v_rod:nv|?????-3/[?????-3]noun:inanim:p:v_zna:nv", tokenizer, tagger);
        assertNotTagged("??????-7");
    }

    @Test
    public void testDynamicTaggingParts() throws IOException {
        TestTools.myAssert("??-?????????", "??-?????????/[??-?????????]adv", tokenizer, tagger);
        TestTools.myAssert("??-?????????", "??-?????????/[??-?????????]adv", tokenizer, tagger);
        TestTools.myAssert("?????-??", "?????-??/[??????]verb:imperf:impr:s:2", tokenizer, tagger);
        TestTools.myAssert("????????-??", "????????-??/[????????]verb:rev:imperf:impr:p:2", tokenizer, tagger);
        TestTools.myAssert("???-??", "???-??/[???]intj", tokenizer, tagger);
        TestTools.myAssert("????-??", "????-??/[????]intj", tokenizer, tagger);
        TestTools.myAssert("?????-??", "?????-??/[??????]verb:imperf:pres:s:2:&insert", tokenizer, tagger);
        TestTools.myAssert("???-????", "???-????/[???-????]adj:m:v_naz:&pron:dem|???-????/[???-????]adj:m:v_zna:rinanim:&pron:dem", tokenizer, tagger);
        TestTools.myAssert("????-????", "????-????/[????]verb:imperf:futr:s:3", tokenizer, tagger);
        TestTools.myAssert("???-????", "???-????/[???]adv:&pron:dem|???-????/[???]part", tokenizer, tagger);
        TestTools.myAssert("?????-????", "?????-????/[?????]adv", tokenizer, tagger);
        TestTools.myAssert("???????-????", "???????-????/[??????]adj:m:v_rod:compb:&numr|???????-????/[??????]adj:m:v_zna:ranim:compb:&numr|???????-????/[??????]adj:n:v_rod:compb:&numr", tokenizer, tagger);
        TestTools.myAssert("?????-????", "?????-????/[?????]noninfl:&predic", tokenizer, tagger);
        // TestTools.myAssert("???????-????", "???????-????/[???????]adv", tokenizer, tagger);
        TestTools.myAssert("????-??", "????-??/[????]adj:m:v_naz:&pron:dem|????-??/[????]adj:m:v_zna:rinanim:&pron:dem", tokenizer, tagger);
        TestTools.myAssert("???-??", "???-??/[???]intj|???-??/[???]part", tokenizer, tagger);
        TestTools.myAssert("????-??", "????-??/[????]adv:&predic", tokenizer, tagger);
        TestTools.myAssert("???????-??", "???????-??/[???????]adj:m:v_naz:&pron:dem:rare|???????-??/[???????]adj:m:v_zna:rinanim:&pron:dem:rare", tokenizer, tagger);
        // TestTools.myAssert("????-??", "????-??/[????]adv", tokenizer, tagger);
        // TestTools.myAssert("????-??", "????-??/[????]adv:compb", tokenizer, tagger);
        TestTools.myAssert("????-??", "????-??/[????]adv:compb|????-??/[?????]adj:n:v_kly:compb|????-??/[?????]adj:n:v_naz:compb|????-??/[?????]adj:n:v_zna:compb", tokenizer, tagger);
        TestTools.myAssert("????-??", "????-??/[????-??]adv", tokenizer, tagger);// TODO: :&pron:ind

        TestTools.myAssert("??????-??", "??????-??/[??????]adj:m:v_naz:&pron:int:rel|??????-??/[??????]adj:m:v_zna:rinanim:&pron:int:rel", tokenizer, tagger);// TODO: :&pron:ind

        TestTools.myAssert("????-??", "????-??/[????]conj:subord", tokenizer, tagger);
        TestTools.myAssert("????-??", "????-??/[????]noun:p:v_naz:&pron:pers:3", tokenizer, tagger);
        TestTools.myAssert("?????-??", "?????-??/[??????]adj:f:v_kly:compb|?????-??/[??????]adj:f:v_naz:compb|?????-??/[?????]noun:inanim:n:v_rod|?????-??/[?????]noun:inanim:p:v_kly|?????-??/[?????]noun:inanim:p:v_naz|?????-??/[?????]noun:inanim:p:v_zna", tokenizer, tagger);
        assertNotTagged("???-??");
        assertNotTagged("??-??");
        assertNotTagged("??-??");
        assertNotTagged("???-??");
        assertNotTagged("???-??");
        assertNotTagged("??-????");
    }

    @Test
    public void testDynamicTaggingXShaped() throws IOException {
        TestTools.myAssert("?-?????????", "?-?????????/[?-????????]adj:m:v_dav:compb|?-?????????/[?-????????]adj:m:v_mis:compb|?-?????????/[?-????????]adj:n:v_dav:compb|?-?????????/[?-????????]adj:n:v_mis:compb", tokenizer, tagger);
        TestTools.myAssert("S-????????", "S-????????/[S-????????]adj:f:v_rod:compb", tokenizer, tagger);
    }

    @Test
    public void testDynamicTaggingPrefixes() throws IOException {
        TestTools.myAssert("VIP????????", "VIP????????/[VIP-???????]noun:inanim:m:v_naz|VIP????????/[VIP-???????]noun:inanim:m:v_zna", tokenizer, tagger);
        TestTools.myAssert("PR-????????????", "PR-????????????/[PR-???????????]noun:inanim:m:v_dav|PR-????????????/[PR-???????????]noun:inanim:m:v_mis|PR-????????????/[PR-???????????]noun:inanim:m:v_rod", tokenizer, tagger);
        TestTools.myAssert("3D-????", "3D-????/[3D-????]noun:inanim:m:v_naz|3D-????/[3D-????]noun:inanim:m:v_zna", tokenizer, tagger);
        TestTools.myAssert("n-?????????", "n-?????????/[n-?????????]adj:m:v_naz|n-?????????/[n-?????????]adj:m:v_zna:rinanim", tokenizer, tagger);
        TestTools.myAssert("?-?????????", "?-?????????/[?-?????????]adj:m:v_naz|?-?????????/[?-?????????]adj:m:v_zna:rinanim", tokenizer, tagger);
        TestTools.myAssert("?-????????", "?-????????/[?-????????]noun:inanim:m:v_naz|?-????????/[?-????????]noun:inanim:m:v_zna", tokenizer, tagger);
        // TestTools.myAssert("POS-???????????", "", tokenizer, tagger);
        // TestTools.myAssert("IT-????????", "IT-????????/[IT-????????]noun:inanim:f:v_dav|IT-????????/[IT-????????]noun:inanim:f:v_mis|IT-????????/[IT-????????]noun:inanim:f:v_rod|IT-????????/[IT-????????]noun:inanim:p:v_naz|IT-????????/[IT-????????]noun:inanim:p:v_zna", tokenizer, tagger);
    }

    @Test
    public void testTwoHypens() throws IOException {
        TestTools.myAssert("?????-????-??????", "?????-????-??????/[?????-????-??????]adj:m:v_kly|?????-????-??????/[?????-????-??????]adj:m:v_naz|?????-????-??????/[?????-????-??????]adj:m:v_zna:rinanim", tokenizer, tagger);
        TestTools.myAssert("??????????-??????????-???????????", "??????????-??????????-???????????/[??????????-??????????-???????????]adj:m:v_oru|??????????-??????????-???????????/[??????????-??????????-???????????]adj:n:v_oru|??????????-??????????-???????????/[??????????-??????????-???????????]adj:p:v_dav", tokenizer, tagger);
        TestTools.myAssert("???????????-??????????-????????????????", "???????????-??????????-????????????????/[?????????-???????????????]adj:m:v_rod|???????????-??????????-????????????????/[?????????-???????????????]adj:m:v_zna:ranim|???????????-??????????-????????????????/[?????????-???????????????]adj:n:v_rod", tokenizer, tagger);
        assertNotTagged("???????-??-??????????");
        // nouns are too complicated
        // TestTools.myAssert("????-???-?????", "????-???-?????/[????-???-?????]noun:inanim:f:v_zna", tokenizer, tagger);
        assertNotTagged("????-????-???");
        // dash-prefix2
        TestTools.myAssert("??-????-????????", "??-????-????????/[??-????-????????]noun:inanim:n:v_naz|??-????-????????/[??-????-????????]noun:inanim:n:v_rod|??-????-????????/[??-????-????????]noun:inanim:n:v_zna|??-????-????????/[??-????-????????]noun:inanim:p:v_naz|??-????-????????/[??-????-????????]noun:inanim:p:v_zna", tokenizer, tagger);
        assertNotTagged("?--???????????");
    }

    @Test
    public void testDynamicTaggingFullTagMatch() throws IOException {
        TestTools.myAssert("???-???????", ("???-???????/[???-???????]noun:inanim:f:v_dav:prop:geo|???-???????/[???-???????]noun:inanim:f:v_mis:prop:geo|???-???????/[???-???????]noun:inanim:f:v_naz:prop:geo" + "|???-???????/[???-???????]noun:inanim:f:v_oru:prop:geo|???-???????/[???-???????]noun:inanim:f:v_rod:prop:geo|???-???????/[???-???????]noun:inanim:f:v_zna:prop:geo"), tokenizer, tagger);
        TestTools.myAssert("????????????-?????", "????????????-?????/[????????????-?????]noun:inanim:f:v_dav:nv:prop|????????????-?????/[????????????-?????]noun:inanim:f:v_mis:nv:prop|????????????-?????/[????????????-?????]noun:inanim:f:v_naz:nv:prop|????????????-?????/[????????????-?????]noun:inanim:f:v_oru:nv:prop|????????????-?????/[????????????-?????]noun:inanim:f:v_rod:nv:prop|????????????-?????/[????????????-?????]noun:inanim:f:v_zna:nv:prop", tokenizer, tagger);
        TestTools.myAssert("????-?????", "????-?????/[????-?????]noun:inanim:f:v_dav:nv:prop|????-?????/[????-?????]noun:inanim:f:v_mis:nv:prop|????-?????/[????-?????]noun:inanim:f:v_naz:nv:prop|????-?????/[????-?????]noun:inanim:f:v_oru:nv:prop|????-?????/[????-?????]noun:inanim:f:v_rod:nv:prop|????-?????/[????-?????]noun:inanim:f:v_zna:nv:prop", tokenizer, tagger);
        // full tag match
        TestTools.myAssert("????-????", "????-????/[????-????]verb:imperf:past:n", tokenizer, tagger);
        TestTools.myAssert("????-????", "????-????/[?????-?????]verb:imperf:pres:s:2", tokenizer, tagger);
        TestTools.myAssert("?-?", "?-?/[?-?]intj", tokenizer, tagger);
        TestTools.myAssert("??-??", "??-??/[??-??]intj", tokenizer, tagger);
        TestTools.myAssert("\u043e\u0441\u044c\u2013\u043e\u0441\u044c", "\u043e\u0441\u044c\u2013\u043e\u0441\u044c/[\u043e\u0441\u044c-\u043e\u0441\u044c]adv", tokenizer, tagger);
        TestTools.myAssert("\u043e\u0441\u044c\u2011\u043e\u0441\u044c", "???-???/[???-???]adv", tokenizer, tagger);
        TestTools.myAssert("\u0406\u0432\u0430\u043d\u043e\u2013\u0424\u0440\u0430\u043d\u043a\u0456\u0432\u0441\u044c\u043a", "????????????????/[?????-??????????]noun:inanim:m:v_naz:prop:geo|????????????????/[?????-??????????]noun:inanim:m:v_zna:prop:geo", tokenizer, tagger);
        TestTools.myAssert("?????-????", "?????-????/[?????-????]adv", tokenizer, tagger);
        TestTools.myAssert("??????-???????", "??????-???????/[??????-???????]noun:inanim:f:v_zna|??????-???????/[??????-???????]noun:inanim:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("????????-??????", "????????-??????/[????????-??????]noun:inanim:m:v_naz|????????-??????/[????????-??????]noun:inanim:p:v_naz", tokenizer, tagger);
        TestTools.myAssert("??????-???????", "??????-???????/[?????-????????]noun:inanim:m:v_rod|??????-???????/[?????-????????]noun:inanim:p:v_rod", tokenizer, tagger);
        // adv-adv
        TestTools.myAssert("????????-????????", "????????-????????/[????????-????????]adv", tokenizer, tagger);
        // adj-adj
        TestTools.myAssert("??????-??????", "??????-??????/[?????-?????]adj:m:v_rod:&pron:def|??????-??????/[?????-?????]adj:m:v_zna:ranim:&pron:def|??????-??????/[?????-?????]adj:n:v_rod:&pron:def", tokenizer, tagger);
        TestTools.myAssert("???????-??????????", "???????-??????????/[???????-??????????]adj:m:v_kly|???????-??????????/[???????-??????????]adj:m:v_naz|???????-??????????/[???????-??????????]adj:m:v_zna:rinanim", tokenizer, tagger);
        TestTools.myAssert("??????-??????", "??????-??????/[??????-??????]adj:f:v_dav|??????-??????/[??????-??????]adj:f:v_mis|??????-??????/[???????-???????]verb:imperf:impr:s:2", tokenizer, tagger);
        TestTools.myAssert("????????-????????????", "????????-????????????/[???????-???????????]adj:m:v_rod:&adjp:pasv:imperf|????????-????????????/[???????-???????????]adj:m:v_zna:ranim:&adjp:pasv:imperf|????????-????????????/[???????-???????????]adj:n:v_rod:&adjp:pasv:imperf", tokenizer, tagger);
        // TODO:
        TestTools.myAssert("?????????????????????", "?????????????????????/[???????-???????????]adj:m:v_rod|?????????????????????/[???????-???????????]adj:m:v_zna:ranim|?????????????????????/[???????-???????????]adj:n:v_rod", tokenizer, tagger);
        // noun-noun
        TestTools.myAssert("?????-????????", "?????-????????/[?????-????????]noun:anim:m:v_naz", tokenizer, tagger);
        TestTools.myAssert("??????-?????????", "??????-?????????/[?????-????????]noun:anim:m:v_rod|??????-?????????/[?????-????????]noun:anim:m:v_zna", tokenizer, tagger);
        TestTools.myAssert("????-????????", "????-????????/[null]null", tokenizer, tagger);
        TestTools.myAssert("?????-???", "?????-???/[null]null", tokenizer, tagger);
        TestTools.myAssert("????-????????", "????-????????/[???-???????]noun:anim:m:v_kly", tokenizer, tagger);
        TestTools.myAssert("??????-???????", "??????-???????/[??????-???????]noun:inanim:m:v_naz|??????-???????/[??????-???????]noun:inanim:m:v_zna", tokenizer, tagger);
        TestTools.myAssert("?????-???????", "?????-???????/[?????-???????]noun:inanim:n:v_rod|?????-???????/[?????-???????]noun:inanim:p:v_naz|?????-???????/[?????-???????]noun:inanim:p:v_zna", tokenizer, tagger);
        // TODO: unanim
        TestTools.myAssert("?????-??????????", "?????-??????????/[null]null", tokenizer, tagger);
        TestTools.myAssert("??????????-???????", "??????????-???????/[null]null", tokenizer, tagger);
        // TestTools.myAssert("???????-???", "???-??????/[???-??????]numr:v_naz|???-??????/[???-??????]numr:v_naz", tokenizer, tagger);
        // TestTools.myAssert("???????-???", "???-??????/[???-??????]numr:v_naz|???-??????/[???-??????]numr:v_naz", tokenizer, tagger);
        // TestTools.myAssert("???????-????", "???-??????/[???-??????]numr:v_naz|???-??????/[???-??????]numr:v_naz", tokenizer, tagger);
        // TestTools.myAssert("??????-??????", "???-??????/[???-??????]numr:v_naz|???-??????/[???-??????]numr:v_naz", tokenizer, tagger);
        TestTools.myAssert("??????-????", "??????-????/[??????-????]noun:inanim:f:v_rod:prop:geo", tokenizer, tagger);
        TestTools.myAssert("????????-?????????????", "????????-?????????????/[????????-?????????????]noun:anim:f:v_naz", tokenizer, tagger);
        TestTools.myAssert("RPM-???????", "RPM-???????/[RPM-???????]noun:inanim:m:v_naz|RPM-???????/[RPM-???????]noun:inanim:m:v_zna", tokenizer, tagger);
        // TODO:
        // TestTools.myAssert("?????????-???", "", tokenizer, tagger);
        assertNotTagged("????-?????");
        assertNotTagged("?????-???????");
        assertNotTagged("??????-????");
        // handled by different logic
        // assertNotTagged("?????-????");
        assertNotTagged("?????-????");
        assertNotTagged("????-???????");
        assertNotTagged("??????????");
        assertNotTagged("???????-??");
        assertNotTagged("?????????-????");
        assertNotTagged("????-??");
        assertNotTagged("???-???");
        assertNotTagged("???-?????");
        assertNotTagged("???????-?????????");// - ???? ?? ???? ????

        assertNotTagged("??????-???");
        assertNotTagged("???-?????");
        assertNotTagged("?????-????????");
        assertNotTagged("????-?????????");
        assertNotTagged("??????-?????");
        assertNotTagged("???-???");
    }

    @Test
    public void testDynamicTaggingIntj() throws IOException {
        TestTools.myAssert("???-???-???", "???-???-???/[???-???-???]intj", tokenizer, tagger);
        TestTools.myAssert("???-??-??-??", "???-??-??-??/[???-??-??-??]intj", tokenizer, tagger);
        // TODO:
        assertNotTagged("??-??-???????");
    }

    @Test
    public void testDynamicTaggingNum() throws IOException {
        // numr-numr
        TestTools.myAssert("?????-?????", "?????-?????/[????-???]numr:p:v_oru", tokenizer, tagger);
        TestTools.myAssert("??????-???????", "??????-???????/[????-??????]numr:m:v_rod:&numr|??????-???????/[????-??????]numr:m:v_zna:ranim:&numr|??????-???????/[????-??????]numr:n:v_rod:&numr", tokenizer, tagger);
        // TODO: ???? ??????? ?????
        // TestTools.myAssert("?'???-?????", "?'???-?????/[?'???-?????]numr:v_dav|?'???-?????/[?'???-?????]numr:v_mis|?'???-?????/[?'???-?????]numr:v_rod", tokenizer, tagger);
        TestTools.myAssert("?'???-?????", "?'???-?????/[?'???-?????]noun:inanim:f:v_rod|?'???-?????/[?'???-?????]noun:inanim:p:v_rod|?'???-?????/[?'???-?????]numr:p:v_dav|?'???-?????/[?'???-?????]numr:p:v_mis|?'???-?????/[?'???-?????]numr:p:v_rod", tokenizer, tagger);
        // TestTools.myAssert("???????-???", "???????-???/[???????-???]numr:f:v_naz|???????-???/[???????-???]numr:f:v_zna", tokenizer, tagger);
        TestTools.myAssert("???-??????", "???-??????/[???-??????]numr:p:v_naz|???-??????/[???-??????]numr:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("???-??????", "???-??????/[???-??????]numr:p:v_naz|???-??????/[???-??????]numr:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("??????-????", "??????-????/[????-???]numr:p:v_mis", tokenizer, tagger);
        TestTools.myAssert("??????????", "??????????/[???-??????]numr:p:v_naz|??????????/[???-??????]numr:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("?????-???", "?????-???/[?????-???]numr:p:v_naz|?????-???/[?????-???]numr:p:v_zna", tokenizer, tagger);
        // noun-numr
        TestTools.myAssert("?????-???", "?????-???/[?????-???]noun:inanim:m:v_naz|?????-???/[?????-???]noun:inanim:m:v_zna|?????-???/[?????-???]noun:inanim:p:v_naz|?????-???/[?????-???]noun:inanim:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("?????-???", "?????-???/[?????-???]noun:inanim:p:v_naz|?????-???/[?????-???]noun:inanim:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("???????-??????", "???????-??????/[??????-???]noun:inanim:f:v_oru:&&numr|???????-??????/[??????-???]noun:inanim:p:v_oru:&&numr|???????-??????/[??????-????]noun:inanim:f:v_oru:&&numr|???????-??????/[??????-????]noun:inanim:p:v_oru:&&numr", tokenizer, tagger);
        TestTools.myAssert("?????-?????", "?????-?????/[??????-??????]adj:n:v_kly:&numr|?????-?????/[??????-??????]adj:n:v_naz:&numr|?????-?????/[??????-??????]adj:n:v_zna:&numr", tokenizer, tagger);
    }

    @Test
    public void testDynamicTaggingFullOthers() throws IOException {
        // others
        // TestTools.myAssert("????-?????", "????-?????/[null]null", tokenizer, tagger);
        TestTools.myAssert("???-???????", "???-???????/[???-???????]noun:anim:m:v_naz", tokenizer, tagger);
        TestTools.myAssert("???????-??????", "???????-??????/[???????-??????]noun:inanim:f:v_naz", tokenizer, tagger);
        TestTools.myAssert("????-???????", "????-???????/[????-???????]noun:inanim:f:v_naz", tokenizer, tagger);
        TestTools.myAssert("????-???????", "????-???????/[????-???????]noun:inanim:f:v_rod|????-???????/[????-???????]noun:inanim:p:v_naz|????-???????/[????-???????]noun:inanim:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("?????????-????????", "?????????-????????/[????????-????????]noun:inanim:f:v_oru", tokenizer, tagger);
        // jr/sr
        TestTools.myAssert("??????-????????", "??????-????????/[?????-???????]noun:anim:m:v_rod:prop:lname|??????-????????/[?????-???????]noun:anim:m:v_zna:prop:lname", tokenizer, tagger);
        // test ranim/rinanim
        // TestTools.myAssert("??????-???????", "??????-???????/[??????-???????]", tokenizer, tagger);
        // TestTools.myAssert("?????-????????", "??????-????????/[??????-????????]", tokenizer, tagger);
        assertNotTagged("???-???");
    }

    @Test
    public void testDynamicTaggingOWithAdj() throws IOException {
        // adv-adj
        TestTools.myAssert("????????-???????????", "????????-???????????/[????????-???????????]adj:m:v_kly|????????-???????????/[????????-???????????]adj:m:v_naz|????????-???????????/[????????-???????????]adj:m:v_zna:rinanim", tokenizer, tagger);
        assertNotTagged("????????-???????????");
        assertNotTagged("????????-???????????");
        assertNotTagged("????????-?????");
        assertNotTagged("????????-??????");
        TestTools.myAssert("???-???????????", "???-???????????/[???-???????????]adj:m:v_kly|???-???????????/[???-???????????]adj:m:v_naz|???-???????????/[???-???????????]adj:m:v_zna:rinanim", tokenizer, tagger);
        TestTools.myAssert("???-??????????????", "???-??????????????/[???-??????????????]adj:m:v_kly|???-??????????????/[???-??????????????]adj:m:v_naz|???-??????????????/[???-??????????????]adj:m:v_zna:rinanim", tokenizer, tagger);
        // :bad
        TestTools.myAssert("?????-????????????????", "?????-????????????????/[?????-????????????????]adj:m:v_kly:bad|?????-????????????????/[?????-????????????????]adj:m:v_naz:bad|?????-????????????????/[?????-????????????????]adj:m:v_zna:rinanim:bad", tokenizer, tagger);
        TestTools.myAssert("????-?????????", "????-?????????/[????-?????????]adj:f:v_dav:bad|????-?????????/[????-?????????]adj:f:v_mis:bad|????-?????????/[????-?????????]adj:m:v_kly:bad|????-?????????/[????-?????????]adj:m:v_naz:bad|????-?????????/[????-?????????]adj:m:v_zna:rinanim:bad", tokenizer, tagger);
        TestTools.myAssert("????????-??????????", "????????-??????????/[????????-??????????]adj:m:v_kly|????????-??????????/[????????-??????????]adj:m:v_naz|????????-??????????/[????????-??????????]adj:m:v_zna:rinanim", tokenizer, tagger);
        TestTools.myAssert("???????-?????????", "???????-?????????/[???????-????????]adj:m:v_rod|???????-?????????/[???????-????????]adj:m:v_zna:ranim|???????-?????????/[???????-????????]adj:n:v_rod", tokenizer, tagger);
        TestTools.myAssert("???????-???????????", "???????-???????????/[???????-???????????]adj:m:v_kly|???????-???????????/[???????-???????????]adj:m:v_naz|???????-???????????/[???????-???????????]adj:m:v_zna:rinanim", tokenizer, tagger);
        TestTools.myAssert("??????-??????????", "??????-??????????/[??????-??????????]adj:f:v_rod:bad", tokenizer, tagger);
        TestTools.myAssert("?????-????????????", "?????-????????????/[?????-????????????]adj:m:v_kly|?????-????????????/[?????-????????????]adj:m:v_naz|?????-????????????/[?????-????????????]adj:m:v_zna:rinanim", tokenizer, tagger);
        // :bad - ??? ???? ??? ??????: "??????????????????"
        TestTools.myAssert("?????-?????????????", "?????-?????????????/[?????-?????????????]adj:m:v_kly:&adjp:pasv:perf:bad|?????-?????????????/[?????-?????????????]adj:m:v_naz:&adjp:pasv:perf:bad|?????-?????????????/[?????-?????????????]adj:m:v_zna:rinanim:&adjp:pasv:perf:bad", tokenizer, tagger);
        assertNotTagged("?????????-?????????");
        assertNotTagged("??-??????????");
        assertNotTagged("?-??????????");
        assertNotTagged("????-????????");
        // TestTools.myAssert("?????????-?????????", "?????????-?????????/[null]null", tokenizer, tagger);
        assertNotTagged("???????-????????");
        assertNotTagged("??????-????????");
        // don't allow dash when the words spelled together
        assertNotTagged("?????????-???????????");
        assertNotTagged("??????-???????????");
        assertNotTagged("??????????-??????");
        assertNotTagged("???????????-???????");// ??? ???? "??????????? ???????"

        // assertNotTagged("??????-?????????"); - ?????????? ????????? "?". ??? ?? ?? ??????? ???????????? - ?????
        // TestTools.myAssert("?????-?????", "?????-?????/[????-??????]noun:anim:p:v_rod", tokenizer, tagger);
        // TestTools.myAssert("?????-?????????", "????-????????", tokenizer, tagger);
    }

    @Test
    public void testDynamicAnimInanim() throws IOException {
        TestTools.myAssert("??????-?????????", "??????-?????????/[??????-???????]noun:anim:p:v_rod|??????-?????????/[??????-???????]noun:anim:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("??????-????????", "??????-????????/[??????-????????]noun:inanim:f:v_naz", tokenizer, tagger);
        TestTools.myAssert("????-????????", "????-????????/[????-????????]noun:inanim:m:v_naz|????-????????/[????-????????]noun:inanim:m:v_zna", tokenizer, tagger);
        TestTools.myAssert("?????-??????", "?????-??????/[????-?????]noun:inanim:p:v_naz|?????-??????/[????-?????]noun:inanim:p:v_zna|?????-??????/[?????-?????]noun:inanim:p:v_naz|?????-??????/[?????-?????]noun:inanim:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("?????-??????", "?????-??????/[?????-??????]noun:inanim:n:v_naz|?????-??????/[?????-??????]noun:inanim:n:v_zna", tokenizer, tagger);
        TestTools.myAssert("??????-????????", "??????-????????/[??????-???????]noun:inanim:p:v_naz|??????-????????/[??????-???????]noun:inanim:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("?????????-??????", "?????????-??????/[?????????-??????]noun:inanim:n:v_naz|?????????-??????/[?????????-??????]noun:inanim:n:v_zna", tokenizer, tagger);
        TestTools.myAssert("???-???????", "???-???????/[???-???????]noun:inanim:m:v_naz|???-???????/[???-???????]noun:inanim:m:v_zna", tokenizer, tagger);
        TestTools.myAssert("?????-???????", "?????-???????/[?????-???????]noun:inanim:m:v_naz|?????-???????/[?????-???????]noun:inanim:m:v_naz|?????-???????/[?????-???????]noun:inanim:m:v_zna|?????-???????/[?????-???????]noun:inanim:m:v_zna", tokenizer, tagger);
        TestTools.myAssert("???????-?????", "???????-?????/[???????-?????]noun:inanim:m:v_naz|???????-?????/[???????-?????]noun:inanim:m:v_naz|???????-?????/[???????-?????]noun:inanim:m:v_zna|???????-?????/[???????-?????]noun:inanim:m:v_zna", tokenizer, tagger);
        TestTools.myAssert("?????????-????????", "?????????-????????/[???????-??????]noun:anim:p:v_rod|?????????-????????/[???????-??????]noun:anim:p:v_zna", tokenizer, tagger);
        TestTools.myAssert("???????-???????", "???????-???????/[???????-???????]noun:anim:p:v_naz", tokenizer, tagger);
        // ??? ??????-??????????
        // TestTools.myAssert("?????-???????",  "", tokenizer, tagger);
        // ???????? ?? ???????-???????
        // ?????????? ?? ?????????-????????
    }

    // TODO:
    // @Test
    // public void testTaggingMultidash() throws IOException {
    // TestTools.myAssert("???????-??????-???????????", "", tokenizer, tagger);
    // TestTools.myAssert("?????-????-??????", "", tokenizer, tagger);
    // TestTools.myAssert("???-???-?????", "", tokenizer, tagger);
    // }
    @Test
    public void testDynamicTaggingNoDash() throws IOException {
        TestTools.myAssert("???????????", ("???????????/[???????????]noun:inanim:f:v_dav:nv:prop|???????????/[???????????]noun:inanim:f:v_mis:nv:prop" + ("|???????????/[???????????]noun:inanim:f:v_naz:nv:prop|???????????/[???????????]noun:inanim:f:v_oru:nv:prop" + "|???????????/[???????????]noun:inanim:f:v_rod:nv:prop|???????????/[???????????]noun:inanim:f:v_zna:nv:prop")), tokenizer, tagger);
    }

    @Test
    public void testDynamicTaggingSkip() throws IOException {
        TestTools.myAssert("?-?-?", "?-?-?/[null]null", tokenizer, tagger);
        TestTools.myAssert("??-??", "??-??/[null]null", tokenizer, tagger);
        TestTools.myAssert("?-?", "?-?/[null]null", tokenizer, tagger);
        TestTools.myAssert("??-????", "??-????/[null]null", tokenizer, tagger);
        TestTools.myAssert("??-??", "??-??/[null]null", tokenizer, tagger);
        // TestTools.myAssert("??-??", "??-??/[??-??]conj:subord:bad", tokenizer, tagger);
        TestTools.myAssert("???-?????", "???-?????/[null]null", tokenizer, tagger);
        TestTools.myAssert("?????-???", "?????-???/[null]null", tokenizer, tagger);
        assertNotTagged("???-??????");
        // \n may happen in words when we have soft-hyphen wrap: \u00AD\n
        // in this case we strip \u00AD but leave \n in the word
        // but this may not happen often, need research if we need this
        // TestTools.myAssert("????\n??", "", tokenizer, tagger);
    }

    @Test
    public void testAltSpelling() throws IOException {
        TestTools.myAssert("???????", "???????/[???????]noun:inanim:m:v_naz:alt|???????/[???????]noun:inanim:m:v_zna:alt", tokenizer, tagger);
        TestTools.myAssert("??????????????", "??????????????/[??????????????]adv:alt", tokenizer, tagger);
        TestTools.myAssert("?????????", "?????????/[?????????]noun:inanim:m:v_naz:alt|?????????/[?????????]noun:inanim:m:v_zna:alt", tokenizer, tagger);
        assertNotTagged("????????");
    }

    @Test
    public void testNapiv() throws IOException {
        TestTools.myAssert("?????'??????", "?????'??????/[?????'??????]noun:anim:f:v_naz", tokenizer, tagger);
        TestTools.myAssert("???????????", "???????????/[???????????]noun:anim:f:v_naz:bad", tokenizer, tagger);
        TestTools.myAssert("?????-??????", "?????-??????/[?????-??????]noun:anim:f:v_naz:bad", tokenizer, tagger);
        TestTools.myAssert("?????-??????", "?????-??????/[?????-??????]noun:inanim:f:v_naz:prop:geo", tokenizer, tagger);
        TestTools.myAssert("?????????????????", "?????????????????/[?????????????????]adj:m:v_kly|?????????????????/[?????????????????]adj:m:v_naz|?????????????????/[?????????????????]adj:m:v_zna:rinanim", tokenizer, tagger);
        TestTools.myAssert("??????????????????", "??????????????????/[?????????????????]adj:m:v_rod:&&adjp:pasv:perf|??????????????????/[?????????????????]adj:m:v_zna:ranim:&&adjp:pasv:perf|??????????????????/[?????????????????]adj:n:v_rod:&&adjp:pasv:perf", tokenizer, tagger);
        TestTools.myAssert("\u043d\u0430\u043f\u0456\u0432\u2013\u0444\u0430\u043d\u0442\u0430\u0441\u0442\u0438\u0447\u043d\u0438\u0445", "??????????????????/[?????-????????????]adj:p:v_mis:bad|??????????????????/[?????-????????????]adj:p:v_rod:bad|??????????????????/[?????-????????????]adj:p:v_zna:ranim:bad", tokenizer, tagger);
        // TODO:
        TestTools.myAssert("??????????????-????????????????", "??????????????-????????????????/[????????-??????????]noun:inanim:f:v_rod|??????????????-????????????????/[?????????-???????????]adj:f:v_rod", tokenizer, tagger);
        // TestTools.myAssert("?????????-????????????", "", tokenizer, tagger);
        assertNotTagged("?????????????????");// typo

        assertNotTagged("??????");
    }
}

