/**
 * *****************************************************************************
 * Copyright (c) 2015-2018 Skymind, Inc.
 *
 * This program and the accompanying materials are made available under the
 * terms of the Apache License, Version 2.0 which is available at
 * https://www.apache.org/licenses/LICENSE-2.0.
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations
 * under the License.
 *
 * SPDX-License-Identifier: Apache-2.0
 * ****************************************************************************
 */
/**
 * -*
 * Copyright ? 2010-2015 Atilika Inc. and contributors (see CONTRIBUTORS.md)
 *
 * Licensed under the Apache License, Version 2.0 (the "License"); you may
 * not use this file except in compliance with the License.  A copy of the
 * License is distributed with this work in the LICENSE.md file.  You may
 * also obtain a copy of the License from
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.atilika.kuromoji.ipadic;


import com.atilika.kuromoji.TestUtils;
import java.io.IOException;
import java.util.Arrays;
import java.util.List;
import org.junit.Assert;
import org.junit.Test;


public class UserDictionaryTokenizerTest {
    private String userDictionary = "" + ((("\u30af\u30ed,\u30af\u30ed,\u30af\u30ed,\u30ab\u30b9\u30bf\u30e0\u540d\u8a5e\n" + "\u771f\u6551\u4e16\u4e3b,\u771f\u6551\u4e16\u4e3b,\u30b7\u30f3\u30ad\u30e5\u30a6\u30bb\u30a4\u30b7\u30e5,\u30ab\u30b9\u30bf\u30e0\u540d\u8a5e\n") + "\u771f\u6551\u4e16\u4e3b\u4f1d\u8aac,\u771f\u6551\u4e16\u4e3b\u4f1d\u8aac,\u30b7\u30f3\u30ad\u30e5\u30a6\u30bb\u30a4\u30b7\u30e5\u30c7\u30f3\u30bb\u30c4,\u30ab\u30b9\u30bf\u30e0\u540d\u8a5e\n") + "????,????,??????,??????");

    @Test
    public void testWhitespace() throws IOException {
        String userDictionary = "iPhone4 S,iPhone4 S,iPhone4 S,??????";
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        String input = "iPhone4 S";
        TestUtils.assertTokenSurfacesEquals(Arrays.asList("iPhone4 S"), tokenizer.tokenize(input));
    }

    @Test(expected = RuntimeException.class)
    public void testBadlyFormattedEntry() throws IOException {
        String entry = "??????,?? ?? ?,???? ????????,??????";
        makeTokenizer(entry);
    }

    @Test
    public void testAcropolis() throws IOException {
        String userDictionary = "??,??,??,??????";
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        String input = "??????";
        TestUtils.assertTokenSurfacesEquals(Arrays.asList("?", "??", "???"), tokenizer.tokenize(input));
    }

    @Test
    public void testAllFeatures() throws IOException {
        String input = "????";
        String[] surfaces = new String[]{ "??", "??" };
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        List<Token> tokens = tokenizer.tokenize(input);
        Assert.assertEquals(surfaces.length, tokens.size());
        Token token = tokens.get(1);
        String actual = ((token.getSurface()) + "\t") + (token.getAllFeatures());
        Assert.assertEquals("\u30af\u30ed\t\u30ab\u30b9\u30bf\u30e0\u540d\u8a5e,*,*,*,*,*,*,\u30af\u30ed,*", actual);
    }

    @Test
    public void testAcropolisInSentence() throws IOException {
        String userDictionary = "??,??,??,??????";
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        String input = "??????????????????";
        TestUtils.assertTokenSurfacesEquals(Arrays.asList("??", "?", "?", "?", "??", "???", "?", "??", "?", "?", "??", "?"), tokenizer.tokenize(input));
    }

    @Test
    public void testLatticeBrokenAfterUserDictEntry() throws IOException {
        String userDictionary = "??,??,??,??????";
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        String input = "????";
        String[] surfaces = new String[]{ "?", "??", "?" };
        String[] features = new String[]{ "*,*,*,*,*,*,*,*,*", "??????,*,*,*,*,*,*,??,*", "*,*,*,*,*,*,*,*,*" };
        List<Token> tokens = tokenizer.tokenize(input);
        for (int i = 0; i < (tokens.size()); i++) {
            Assert.assertEquals(surfaces[i], tokens.get(i).getSurface());
            Assert.assertEquals(features[i], tokens.get(i).getAllFeatures());
        }
    }

    @Test
    public void testLatticeBrokenAfterUserDictEntryInSentence() throws IOException {
        String userDictionary = "??,??,??,??????,a,a,a";
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        String input = "?????????????";
        String[] surfaces = new String[]{ "??", "?", "?", "??", "?", "?", "??", "?", "?", "?" };
        String[] features = new String[]{ "???,*,*,*,*,*,??,??,??", "??,??,*,*,*,*,?,??,??", "??,???,*,*,*,*,?,?,?", "??,??,*,*,*,*,??,???,???", "??,???,*,*,*,*,?,?,?", "*,*,*,*,*,*,*,*,*", "??????,*,*,*,*,*,*,??,*", "*,*,*,*,*,*,*,*,*", "???,*,*,*,????,???,?,?,?", "??,??,*,*,*,*,?,?,?" };
        List<Token> tokens = tokenizer.tokenize(input);
        for (int i = 0; i < (tokens.size()); i++) {
            Assert.assertEquals(surfaces[i], tokens.get(i).getSurface());
            Assert.assertEquals(features[i], tokens.get(i).getAllFeatures());
        }
    }

    @Test
    public void testShinKyuseishu() throws IOException {
        String userDictionary = "????,????,?????????,??????";
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        Assert.assertEquals("?????????", tokenizer.tokenize("??????").get(0).getReading());
    }

    @Test
    public void testShinKyuseishuDensetsu() throws IOException {
        String userDictionary = "??????,??????,?????????????,??????";
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        Assert.assertEquals("?????????????", tokenizer.tokenize("??????").get(0).getReading());
    }

    @Test
    public void testCheckDifferentSpelling() throws IOException {
        String input = "??????????????????";
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        List<Token> tokens = tokenizer.tokenize(input);
        String[] expectedReadings = new String[]{ "??????", "?", "?????????????", "?", "?????", "?", "??", "?" };
        for (int i = 0; i < (tokens.size()); i++) {
            Assert.assertEquals(expectedReadings[i], tokens.get(i).getReading());
        }
    }

    @Test
    public void testLongestActualJapaneseWord() throws IOException {
        String userDictionary = "?????????????,?????????????,?????????????????????,??????";
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        Assert.assertEquals("?????????????????????", tokenizer.tokenize("?????????????").get(0).getReading());
    }

    @Test
    public void testLongestMovieTitle() throws IOException {
        String userDictionary = "???????????????????????????????????????????????????????," + (("???????????????????????????????????????????????????????," + "??????????????????????????????????????????????????????????????????????,") + "??????");
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        Assert.assertEquals("??????????????????????????????????????????????????????????????????????", tokenizer.tokenize("???????????????????????????????????????????????????????").get(0).getReading());
    }

    @Test
    public void testInsertedFail() throws IOException {
        String userDictionary = "\u5f15,\u5f15,\u5f15,\u30ab\u30b9\u30bf\u30e0\u54c1\u8a5e\n";
        Tokenizer tokenizer = makeTokenizer(userDictionary);
        TestUtils.assertTokenSurfacesEquals(Arrays.asList("?", "?", "?"), tokenizer.tokenize("???"));
    }
}

